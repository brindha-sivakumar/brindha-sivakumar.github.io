---
title: "Explainable AI for Network Intrusion Detection"
excerpt: "Applying Causal Inference and XAI to improve alert prioritization in NIDS<br/><img src='/images/nids-project.png' width='500'>"
collection: portfolio
---

## Overview
This research project applies Explainable AI techniques and Causal Inference to improve the interpretability and effectiveness of Network Intrusion Detection Systems (NIDS).

## Problem Statement
Traditional NIDS generate high volumes of alerts with limited context, leading to alert fatigue and missed threats. Security analysts need to understand WHY a system flagged something as malicious.

## Approach
- Applied SHAP and LIME for model explanations
- Implemented causal inference to identify true threat indicators
- Built comparative analysis of explanation quality across different ML models

## Technologies Used
- Python, PyTorch, scikit-learn
- SHAP, LIME for explainability
- Network traffic datasets (NSL-KDD, CICIDS2017)

## Results
- Improved alert prioritization accuracy by X%
- Reduced false positive investigation time
- Created interpretable feature importance rankings

## Links
- [GitHub Repository](#)
- [Research Paper](#)
- [Demo Video](#)

